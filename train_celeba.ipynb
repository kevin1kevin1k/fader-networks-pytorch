{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.celeba_dataset import CelebA\n",
    "from src.fadernet import Encoder,Decoder,Discriminator\n",
    "%matplotlib inline\n",
    "\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "\n",
    "data_path = 'data/img/'\n",
    "spliting_path = '/home/alexliu/Downloads/CelebA/Eval/list_eval_partition.txt'\n",
    "attribute_path = '/home/alexliu/Downloads/CelebA/Anno/list_attr_celeba.txt'\n",
    "\n",
    "\n",
    "\n",
    "# Training Config\n",
    "use_cpu_cores = 6\n",
    "num_epoch = 100\n",
    "display_step = 100\n",
    "plot_step = 1000\n",
    "batch_size = 32\n",
    "LEARNING_RATE = 2e-4\n",
    "betas=(0.5, 0.999)\n",
    "final_lambda = 1e-4\n",
    "increase_step = 500000\n",
    "increase_lambda = final_lambda/increase_step\n",
    "\n",
    "# Logger & Debug\n",
    "exp_name = 'FaderNet_Male'\n",
    "\n",
    "num_test_fig = 10\n",
    "save_fig = True\n",
    "save_fig_path = 'fig/'+exp_name+'_step_{}.jpg'\n",
    "step_msg = 'Epoch {}\\tGlobStep {}\\tMSE {:.4f}\\tBCE {:.4f}\\tadv {:.4f}\\t'\n",
    "\n",
    "save_model = True\n",
    "save_model_interval = 10000\n",
    "save_model_path = 'checkpoint/'+exp_name+'_{}'\n",
    "\n",
    "save_log = True\n",
    "save_log_path = 'log/'+exp_name+'.log'\n",
    "log_msg = '{},{:.4f},{:.4f},{:.4f}'\n",
    "if save_log:\n",
    "    log_file = open(save_log_path,'w')\n",
    "    log_file.write('step,MSE,BCE,ADV\\n')\n",
    "\n",
    "for path in ['fig/', 'checkpoint/', 'log/']:\n",
    "    os.makedirs(path)\n",
    "\n",
    "# Model Config\n",
    "target_attr = 'Male'\n",
    "k_list = [3, 16, 32, 64, 128, 256, 512, 512]\n",
    "IMAGE_SIZE = 256\n",
    "num_tags = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "Currently using single attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Attribute table & split dataset\n",
    "attri_table = pd.read_csv(attribute_path,sep=' * ',skiprows=1)\n",
    "# attri_table['Male'].value_counts()\n",
    "# attri_table.columns\n",
    "split = pd.read_csv(spliting_path,header=None,sep=' ',index_col=0)\n",
    "split = split.rename(columns={1:'Set'}).join(attri_table[target_attr])\n",
    "split[target_attr] = split[target_attr]==1\n",
    "\n",
    "\n",
    "\n",
    "# Read the spliting table & split dataset\n",
    "\n",
    "train_set = [(idx.split('.')[0]+'.png',[1*row[target_attr],1*(not row[target_attr])]) \n",
    "             for idx,row in split.loc[split['Set']==0].iterrows()]\n",
    "valid_set = [(idx.split('.')[0]+'.png',[1*row[target_attr],1*(not row[target_attr])]) \n",
    "             for idx,row in split.loc[split['Set']==1].iterrows()]\n",
    "test_set = [(idx.split('.')[0]+'.png',[1*row[target_attr],1*(not row[target_attr])]) \n",
    "             for idx,row in split.loc[split['Set']==2].iterrows()]\n",
    "\n",
    "\n",
    "# Create Dataset\n",
    "train_set = DataLoader(CelebA(train_set,data_path), \n",
    "                       batch_size=batch_size, shuffle=True, num_workers=use_cpu_cores, drop_last=True)\n",
    "debug_set = DataLoader(CelebA(test_set[:num_test_fig],data_path), \n",
    "                       batch_size=num_test_fig, shuffle=False, num_workers=1, drop_last=False)\n",
    "\n",
    "print('Training 1 epoch =',len(train_set),'steps')\n",
    "print('Training for',num_epoch*len(train_set),'steps')\n",
    "\n",
    "del attri_table\n",
    "del split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Variable(torch.zeros(batch_size, 3, IMAGE_SIZE, IMAGE_SIZE).float(),requires_grad=False)\n",
    "given_attr = Variable(torch.zeros(batch_size, num_tags),requires_grad=False)\n",
    "flipped_attr = Variable(torch.zeros(batch_size, num_tags),requires_grad=False)\n",
    "\n",
    "test_img = Variable(torch.zeros(num_test_fig, 3, IMAGE_SIZE, IMAGE_SIZE).float(),requires_grad=False)\n",
    "test_attr = Variable(torch.zeros(num_test_fig, num_tags),requires_grad=False)\n",
    "\n",
    "enc = Encoder(k_list)\n",
    "dec = Decoder(k_list, num_tags, image_size=IMAGE_SIZE)\n",
    "dis = Discriminator(num_tags)\n",
    "\n",
    "reconstruct_loss = nn.MSELoss()\n",
    "classification_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "if use_cuda:\n",
    "    input_img = input_img.cuda()\n",
    "    given_attr = given_attr.cuda()\n",
    "    flipped_attr = flipped_attr.cuda()\n",
    "    test_img = test_img.cuda()\n",
    "    test_attr = test_attr.cuda()\n",
    "    enc = enc.cuda()\n",
    "    dec = dec.cuda()\n",
    "    reconstruct_loss = reconstruct_loss.cuda()\n",
    "    classification_loss = classification_loss.cuda()\n",
    "    dis = dis.cuda()\n",
    "\n",
    "opt_enc_dec = optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=LEARNING_RATE, betas=betas)\n",
    "opt_dis = optim.Adam(dis.parameters(), lr=LEARNING_RATE, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "adversarial_lambda = 0.0\n",
    "bce_history = []\n",
    "mse_history = []\n",
    "adv_history = []\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    for (batch_img,batch_attr) in train_set:\n",
    "        \n",
    "        # Load batch\n",
    "        input_img.data.copy_(batch_img)\n",
    "        given_attr.data.copy_(batch_attr)\n",
    "        flipped_attr.data.copy_(1-batch_attr)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        opt_dis.zero_grad()\n",
    "        \n",
    "        E_x = enc(input_img)\n",
    "        pred_attr = dis(E_x.detach())\n",
    "        dis_loss = classification_loss(pred_attr,given_attr)\n",
    "        \n",
    "        dis_loss.backward()\n",
    "        opt_dis.step()\n",
    "        \n",
    "        # Train AE\n",
    "        opt_enc_dec.zero_grad()\n",
    "\n",
    "        pred_attr_to_fool = dis(E_x)\n",
    "        reconstruct_img = dec(E_x,given_attr)\n",
    "        \n",
    "        adv_loss = classification_loss(pred_attr_to_fool,flipped_attr)\n",
    "        rec_loss = reconstruct_loss(reconstruct_img,input_img)\n",
    "        \n",
    "        loss = rec_loss + adversarial_lambda*adv_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        opt_enc_dec.step()\n",
    "        \n",
    "        # End of step\n",
    "        bce_history.append(dis_loss.cpu().data.numpy()[0])\n",
    "        mse_history.append(rec_loss.cpu().data.numpy()[0])\n",
    "        adv_history.append(adv_loss.cpu().data.numpy()[0])\n",
    "        global_step += 1\n",
    "        \n",
    "        ### Increase Lambda\n",
    "        if global_step < increase_step:\n",
    "            adversarial_lambda += increase_lambda\n",
    "        \n",
    "        ### Display progress\n",
    "        if global_step%display_step == 0:\n",
    "            print(step_msg.format(epoch+1,global_step,np.mean(mse_history),np.mean(bce_history),np.mean(adv_history)),\n",
    "                  end='\\r',flush=True)\n",
    "            if save_log:\n",
    "                print(log_msg.format(global_step,np.mean(mse_history),np.mean(bce_history),np.mean(adv_history)),\n",
    "                     end='\\n',flush=True,file=log_file)\n",
    "            bce_history = []\n",
    "            mse_history = []\n",
    "            adv_history = []\n",
    "        \n",
    "        ### Show result\n",
    "        if global_step% plot_step ==0:\n",
    "            # Run test\n",
    "            for (batch_img,batch_attr) in debug_set:\n",
    "                test_img.data.copy_(batch_img)\n",
    "                test_attr.data.copy_(batch_attr)\n",
    "                reconstruct_img = dec(enc(test_img),test_attr)\n",
    "                \n",
    "                test_attr.data.copy_(1-batch_attr)\n",
    "                flipped_img = dec(enc(test_img),test_attr)\n",
    "            # Show result\n",
    "            tmp = []\n",
    "            src_image = [(1+img)/2 for img in test_img.cpu().data.numpy().transpose(-4,-2,-1,-3)]\n",
    "            rec_image = [(1+img)/2 for img in reconstruct_img.cpu().data.numpy().transpose(-4,-2,-1,-3)]\n",
    "            flp_image = [(1+img)/2 for img in flipped_img.cpu().data.numpy().transpose(-4,-2,-1,-3)]\n",
    "            tmp.append(np.concatenate(src_image,axis=-2))\n",
    "            tmp.append(np.concatenate(rec_image,axis=-2))\n",
    "            tmp.append(np.concatenate(flp_image,axis=-2))\n",
    "            fig = plt.figure(figsize=(20, 10))\n",
    "            tmp = np.squeeze(np.concatenate(tmp,axis=-3))\n",
    "            plt.imshow(tmp)\n",
    "            # plt.show()\n",
    "            if save_fig:\n",
    "                plt.savefig(save_fig_path.format(global_step),bbox_inches='tight')\n",
    "            plt.close()\n",
    "        \n",
    "        ### Save model\n",
    "        if global_step % save_model_interval == 0:\n",
    "            torch.save(enc,save_model_path.format(global_step)+'.enc')\n",
    "            torch.save(dec,save_model_path.format(global_step)+'.dec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
